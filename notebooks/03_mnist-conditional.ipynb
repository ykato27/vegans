{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32e9a0a5",
   "metadata": {},
   "source": [
    "# Conditional MNIST example\n",
    "\n",
    "In the last notebook we looked at the creation of handwritten digits. However we could not control which numbers where generated because we had no idea how the GAN mapped the different digits from 0-9 in the latent space. In this tutorial where forcing the network to learn a specific distribution for every digit such that we have control over the output when generating new examples. Note that this comes at a cost: While so far all examples where performed in an unsupervised way (menaing you didn't use the labels of the data) this approach needs labeled data.\n",
    "\n",
    "First import the usual libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b545fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import vegans.utils.loading as loading\n",
    "from vegans.GAN import ConditionalWassersteinGAN, ConditionalWassersteinGANGP\n",
    "from vegans.utils.utils import plot_losses, plot_images, get_input_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978cd6f1",
   "metadata": {},
   "source": [
    "Check if your machine has an available GPU for usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0813a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cuda is available: {}'.format(torch.cuda.is_available()))\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4e7c57",
   "metadata": {},
   "source": [
    "Now download the mnist dataset and set the parameters below (To get exactly the same format as in this tutorial download from [here](https://github.com/tneuer/GAN-pytorch/tree/main/data/mnist), but of course you can load it from anywhere you want):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d309299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory used to store the data\n",
    "datapath = \"./data\"\n",
    "\n",
    "# Hidden layer channels for generator / critic\n",
    "ngf = 8\n",
    "ncf = 4\n",
    "\n",
    "# Padding for mnist images (28x28) -> (32x32)\n",
    "pad = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c19eaee",
   "metadata": {},
   "source": [
    "Now load and preprocess the data:\n",
    "- The images are saved in gray scale from 0-255, so we scale it to 0-1. Then we can use a Sigmoid as the last layer of the generator.\n",
    "- The original image shape is (28, 28) but when working with convolutional layers it is often beneficial to have a power of two. Therefore we pad two empty rows and columns to every image.\n",
    "- Finally we reshape the images because we need the images in the shape of (nr_channels, nr_heiht_pixels, nr_width_pixels). In out case this results in [1, 32, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9717130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Create dataset\n",
    "\"\"\"\n",
    "X_train, y_train, X_test, y_test = loading.load_data(datapath, which=\"mnist\", download=True)\n",
    "    \n",
    "X_train = X_train / np.max(X_train)\n",
    "X_test = X_test / np.max(X_test)\n",
    "X_train = X_train.reshape((-1, 1, 32, 32))\n",
    "X_test = X_test.reshape((-1, 1, 32, 32))\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c27afa",
   "metadata": {},
   "source": [
    "Now we plot the handwritten digits, this time using the labels because we anyway need them later for this supervised algortihm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca40f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_images(images=X_train.reshape(-1, 32, 32), labels=y_train, n=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c899fafc",
   "metadata": {},
   "source": [
    "We need to pass the labels as one hot encoded vectors so we use the numpy to transform the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2563aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = len(set(y_train))\n",
    "y_train = np.eye(nb_classes)[y_train.reshape(-1)]\n",
    "y_test = np.eye(nb_classes)[y_test.reshape(-1)]\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293d23a4",
   "metadata": {},
   "source": [
    "We now define all the different input sizes for the discriminator and generator. Note that internally the images X_train are concatenated with the labels before passing them to the discriminator / critic. The labels are also concatenated with the noise so that the generator as well as the adversary can learn to differentiate between images of different digits. To calculate the number of input channels / features we can use a utility functiion called `get_input_dim(dim1, dim2)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf13841",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = X_train.shape[1:]\n",
    "y_dim = y_train.shape[1:]\n",
    "z_dim = [1, 4, 4]\n",
    "\n",
    "print(\"x_dim:\", x_dim, \"y_dim:\", y_dim, \"z_dim:\", z_dim)\n",
    "adv_in_dim = get_input_dim(dim1=x_dim, dim2=y_dim)\n",
    "gen_in_dim = get_input_dim(dim1=z_dim, dim2=y_dim)\n",
    "print(\"Adv_dim:\", adv_in_dim, \"Gen_dim:\", gen_in_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071440e6",
   "metadata": {},
   "source": [
    "Note that the labels get concatenated with the channel axis of both the `z_dim` and `x_dim`. You could choose for `z_dim` a single integer as well and it would return the correct amount of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58469cb2",
   "metadata": {},
   "source": [
    "### Definition of Generator and Discriminator / Critic\n",
    "We'll specify the architecture of the generator and discriminator / critic networks. It's difficult to know which architectures to choose before training. Here we used a architecture which proved to work.\n",
    "\n",
    "Since we want to train a Wasserstein GAN, the output of the critic should be a real number and not a probability. Therefore we drop the last sigmoid and use the identity function. If you want to switch to a architecture that uses a discriminator switch the `nn.Identity` with `nn.Sigmoid` for the adversary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc994ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Generator\n",
    "\"\"\"\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        ngf = 20\n",
    "        nc = 1\n",
    "        self.hidden_part = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=gen_in_dim[0], out_channels=ngf * 8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(ngf * 2, ngf * 2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(ngf, ngf, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, nc, 5, 1, 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(nc, nc, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden_part(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "\"\"\" Adversary\n",
    "\"\"\"\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        ncf = 8\n",
    "        self.hidden_part = nn.Sequential(\n",
    "            # input is (nc) x 32 x 32\n",
    "            nn.Conv2d(in_channels=adv_in_dim[0], out_channels=ncf, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ncf) x 16 x 16\n",
    "            nn.Conv2d(ncf, ncf * 2, 4, 2, 1),\n",
    "            nn.BatchNorm2d(ncf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ncf*2) x 8 x 8\n",
    "            nn.Conv2d(ncf * 2, ncf * 4, 4, 2, 1),\n",
    "            nn.BatchNorm2d(ncf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ncf*4) x 4 x 4\n",
    "            nn.Conv2d(ncf * 4, ncf * 8, 4, 2, 1),\n",
    "            nn.BatchNorm2d(ncf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ncf*8) x 2 x 2\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=ncf*8*2*2, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32, out_features=1)\n",
    "        )\n",
    "        self.output = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden_part(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "generator = Generator()\n",
    "critic = Critic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64eefa4",
   "metadata": {},
   "source": [
    "### Train our GAN\n",
    "Build a Wasserstein GAN trainer, using default optimizers (we can also specify our own). To use a different GAN algorithm, just use the corresponding class (e.g., `VanillaGAN` for original GAN).\n",
    "\n",
    "Here you can specify some optional GAN parameters, such as the latent space dimension `z_dim`, the number of samples to save (`fixed_noise_size`) and the optimizer keyword arguments (`optim_kwargs`). We set `folder=None` so that no folder is created where all results would be stored. Otherwise we could give a path like `folder=\"TrainedModels/GAN\"`. All results (summary, images, loss functions, tensorboard information, models) would be saved in that folder. You can control what should be saved in the `fit` method. This folder will never overwrite an existing folder. If the path already exists a new path of the form `folder=path_{TimeStamp}` is created.\n",
    "\n",
    "We also decrease the learning rate of the critic a little.\n",
    "For this conditional algorithm we also need to pass in the dimension of the one hot encoded labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09de1949",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_kwargs = {\"Generator\": {\"lr\": 0.0005}, \"Adversary\": {\"lr\": 0.0001}}\n",
    "gan = ConditionalWassersteinGAN(\n",
    "    generator, critic, z_dim=z_dim, x_dim=x_dim, y_dim=y_dim,\n",
    "    optim_kwargs=optim_kwargs, fixed_noise_size=20, folder=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a248608",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410860b3",
   "metadata": {},
   "source": [
    "Train the networks by calling the `fit()` method. Here you can specify some parameters for training like `eochs`, `batch_size`, `save_model_every`, `save_images_every`, `print_every`, `enable_tensorboard` and others.\n",
    "\n",
    "You can interrupt training at any time and still access train stats from within the `gan` object. You can resume training later. Note that we increase the number of steps the critic (adversary) is trained, which is common for Wasserstein GANs but not VanillaGANs so take care when switching out algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746bab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = {\"Adversary\": 5}\n",
    "gan.fit(\n",
    "    X_train, y_train, X_test, y_test, epochs=5, steps=steps,\n",
    "    print_every=\"0.25e\", save_losses_every=10, enable_tensorboard=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631f331b",
   "metadata": {},
   "source": [
    "Investigate the results and loss curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c205022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, losses = gan.get_training_results()\n",
    "fig, axs = plot_losses(losses)\n",
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0eb8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_labels = np.argmax(gan.fixed_labels.cpu().detach().numpy(), axis=1)\n",
    "fig, axs = plot_images(samples.reshape(-1, 32, 32), n=9, labels=fixed_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3362955e",
   "metadata": {},
   "source": [
    "Now we want to generate new images and have control over the number of generated images. Note that the `get_training_results` returns as many images as were specified with the `fixed_noise_size` argument in the constructor when creating the GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6d1d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_labels = np.zeros(shape=(10, 10))\n",
    "np.fill_diagonal(my_labels, 1)\n",
    "new_samples = gan.generate(y=my_labels)\n",
    "print(new_samples.shape)\n",
    "fig, axs = plot_images(samples.reshape(-1, 32, 32), labels=list(range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4050c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

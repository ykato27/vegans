{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06b0a64e",
   "metadata": {},
   "source": [
    "# Creating your own GAN I: LSGAN\n",
    "\n",
    "In this notebook you will learn how to create your own Generative Adversarial Network with `vegans`. This is a more advanced topic which gives you deeper insights into the design of the library. If you do not want to implement your own networks it might still be worth reading through the next couple of notebooks to get a deeper understanding of what's happening in the background. If you're not interested in that it's fine as well and you can work with the already implemented models :) As the time of writing this notebook (2021-04-08 08:32) there are only 3 (6) GAN architectures implemented in `vegans`: `VanillaGAN`, `WasssersteinGAN`, `WassersteinGANGP` and all there conditional variants. In this notebook I will explain to you how to implement the `LSGAN` and `ConditionalLSGAN` (which will then probably be part of the library after finishing this notebook), which stands for [Least-Squares GAN](https://arxiv.org/abs/1611.04076v3). In the next few tutorials we will create successively implement more difficult architectures (Pix2Pix, LR-GAN).\n",
    "\n",
    "First import the usual libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52704b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from vegans.GAN import ConditionalWassersteinGAN, ConditionalWassersteinGANGP\n",
    "from vegans.utils.utils import plot_losses, plot_images, get_input_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df115445",
   "metadata": {},
   "source": [
    "## AbstractGenerativeModel\n",
    "\n",
    "We will first implement the unconditional variant of the `LSGAN`, investigate the base classes to be used and the move on to the conditional version.\n",
    "\n",
    "The most important class in `vegans` is the `AbstractGenerativeModel`. It takes care of a lot of boilerplate code for logging and saving stuff, checking for the correct input and defining the correct variables. Every unconditional model (and also conditional model for that matter) should inherit from this class. It is semi-abstract in the sense that the `AbstractGenerativeModel` itself can not be used for training anything as it's missing some important functions which MUST be implemented by its children. \n",
    "\n",
    "These **abstract methods** are\n",
    "- \\_\\_init\\_\\_(self, x_dim, z_dim, optim, optim_kwargs, fixed_noise_size, device, folder, ngpu):\n",
    "    This takes care of the initializaton and the method \n",
    "    \n",
    "    super().\\_\\_init\\_\\_(\n",
    "        x_dim=x_dim, z_dim=z_dim, optim=optim, optim_kwargs=optim_kwargs,\n",
    "        fixed_noise_size=fixed_noise_size, device=device, folder=folder, ngpu=ngpu\n",
    "     )\n",
    "     \n",
    "     must be called at the end of the `__init__` method.\n",
    "\n",
    "- _define_loss(self): Not strictly necessary but it is still kept as an abstract method so that the user has to think about what he wants to implement here. You can also implement it with a single `pass` statement. However, we will show you it's intended use here.\n",
    "\n",
    "- calculate_losses(self, X_batch, Z_batch, who): The core function that needs to be implemented. For every batch it must populate an already existing (but empty) dictionary `self._losses`. The keys of the dictionary must include at least the keys used in `self.neural_nets` (explained below), but can also contain other losses. We will discuss this further in later implementations.\n",
    "\n",
    "The `AbstractGenerativeModel` will also check for the presence of one very **important** attribute:\n",
    "- self.neural_nets: This is a dictionary containing all the different networks to be trained. It might look like\n",
    "    {\n",
    "        \"Generator\": generator_nn_Module,\n",
    "        \"Adversary\": adversary_nn_Module,\n",
    "        \"Encoder\": encoder_nn_Module\n",
    "    }\n",
    "\n",
    "The values of the dictionary must inherit in one way or another from `nn.Module`. The user of the implemented GAN must make sure of that by using `nn.Sequential` or building their own architectures which inherit from `nn.Module` (like shown in all previous tutorials).\n",
    "\n",
    "The keys of the dictionary are equally as important because these will link together different parts used during training, for example:\n",
    "- self.optimizers: dict containing the same keys as `self.neural_nets`. Containing one optimizer per network.\n",
    "- self.steps: dict containing the same keys as `self.neural_nets`. Containing the number of training steps per network.\n",
    "- self._losses: dict containing the same keys as `self.neural_nets`. Containing the loss functions per network.\n",
    "\n",
    "Which key will be used per training step is determined by the `who`argument of `calculate_losses`. In this example case `who` will be one of \"Generator\", \"Adversary\" or \"Encoder\". In the `fit` function of the AbstractGenerativeModel we have the following code snippet, which should now make sense:\n",
    "\n",
    "```python\n",
    "for name, _ in self.neural_nets.items():     # iterates over [\"Generator\", \"Adversary\", \"Encoder\"]\n",
    "    for _ in range(self.steps[name]):        # Train every network for its specified steps\n",
    "        self._losses = {}                    # Empty _losses dictionary\n",
    "        self.calculate_losses(X_batch=X, Z_batch=Z, who=name) # populate _losses dictionary / USER-DEFINED\n",
    "        self._zero_grad(who=name)            # Set appropriate gradients to zero\n",
    "        self._backward(who=name)             # Calculate the gradients for a certain loss \n",
    "        self._step(who=name)                 # Propagate the update through the network\n",
    "```\n",
    "\n",
    "Here we iterate over all existing keys in `self.neural_nets` ([\"Generator\", \"Adversary\", \"Encoder\"]). We use this key to fetch the number of steps this network should be trained for. We then create an empty `self._losses` dictionary which **MUST** be populated when calling `sef.calculate_losses`. After that we call the usual torch functions to set the previous gradients to zero, calculate the gradients and propagate those through the network.\n",
    "\n",
    "Now we covered most of the important things. They will be explained again at the appropriate position over the course of the next few notebooks whenever they become relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091fb561",
   "metadata": {},
   "source": [
    "## AbstractGAN1v1\n",
    "\n",
    "We can almost start with the implementation of the LSGAN. There exists one more utility class which is not as abstract as `AbstractGenerativeModel` (it in fact inherits from `AbstractGenerativeModel`) but it is not yet a true `GAN` implementation. This is the `AbstractGAN1v1` which should be used whenever you want to implement a `GAN` of the structure \n",
    "\n",
    "```python\n",
    "self.neural_nets = {\n",
    "    \"Generator\": generator_nn_Module,\n",
    "    \"Adversary\": adversary_nn_Module\n",
    "}\n",
    "```\n",
    "\n",
    "So one generator vs one adversary. This includes the VanillaGAN, WassersteinGAN, WassersteinGANGP as well as the LSGAN. It already implements the `calculate_losses` abstract method (which can be overriden of course) and takes care of initialization. So implementing LSGAN becomes very easy. More advanced cases are in the next notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e52c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vegans.models.unconditional.AbstractGAN1v1 import AbstractGAN1v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a682c1",
   "metadata": {},
   "source": [
    "## LSGAN\n",
    "\n",
    "Now let's with the class definition and `__init__` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50d9e041",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSGAN(AbstractGAN1v1):\n",
    "    def __init__(\n",
    "            self,\n",
    "            generator,\n",
    "            adversary,\n",
    "            x_dim,\n",
    "            z_dim,\n",
    "            optim=None,\n",
    "            optim_kwargs=None,\n",
    "            feature_layer=None,\n",
    "            fixed_noise_size=32,\n",
    "            device=None,\n",
    "            folder=\"./LSGAN\",\n",
    "            ngpu=None):\n",
    "\n",
    "        super().__init__(\n",
    "            generator=generator, adversary=adversary,\n",
    "            z_dim=z_dim, x_dim=x_dim, adv_type=\"Discriminator\",\n",
    "            optim=optim, optim_kwargs=optim_kwargs, feature_layer=feature_layer,\n",
    "            fixed_noise_size=fixed_noise_size,\n",
    "            device=device, folder=folder, ngpu=ngpu\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae995c21",
   "metadata": {},
   "source": [
    "This is basically a copy of the code for the [VanillaGAN](https://github.com/tneuer/GAN-pytorch/blob/main/vegans/models/unconditional/VanillaGAN.py). We do not need to inherit from `AbstractGenerativeModel` explicitly because this is already done by `AbstractGAN1v1`.\n",
    "\n",
    "As for all networks we expect an optim(izer) dictionary, optim_kwargs (optimizer keyword arguments), fixed_noise_size (for logging purposes), the device (\"cpu\" or \"cuda\"), folder and ngpu (number gpus). We simply pass this to the parent class [AbstractGAN1v1](https://github.com/tneuer/GAN-pytorch/blob/main/vegans/models/unconditional/AbstractGAN1v1.py) which will immediatly create the very important\n",
    "\n",
    "`self.neural_nets = {\"Generator\": self.generator, \"Adversary\": self.adversary}`\n",
    "\n",
    "You are bound by these names (\"Generator\", \"Adversary\") if you are using `AbstractGAN1v1`. If you don't like them you need to implement a little bit more (next notebooks).\n",
    "\n",
    "Notice that we used `adv_type=\"Discriminator\"` which indicates that the `adversary` must output a value between [0, 1]. This will be checked when the user passes an adversary architecture. If you want the output to be between [-Inf, Inf] use `adv_type=\"Critic\"`.\n",
    "\n",
    "The argument `feature_layer` enables the usage of a feature loss for the generator overwriting the default loss function. In this case this would of course be the Least Squares loss. \n",
    "\n",
    "Because it is so simple we will implement the missing method `_define_loss` in one go. The loss function must take two arguments:\n",
    "\n",
    "- output from discriminator (or critic) -> prediction\n",
    "- real and false labels. They will be generated by the `AbstractGAN1v1` and are either arrays full of ones or zeros -> labels\n",
    "\n",
    "For the LSGAN (Least-Squares GAN) we use the Mean-Squared-Error loss given by:\n",
    "\n",
    "Discriminator: 0.5 \\* ( (D(x) - b)\\*\\*2 + (D(G(z)) - a)\\*\\*2 )\n",
    "\n",
    "Generator: 0.5 \\*  (D(G(z)) - c)\\*\\*2 \n",
    "\n",
    "where D(x) is the discriminator output for real images (predictions), G(z) is the generator output and a, b, c are parameters. Very often we set a=0, b=c=1. This is what we will do in our implementation. This results in:\n",
    "\n",
    "Discriminator: 0.5 \\* ( (D(x) - 1)\\*\\*2 + D(G(z)\\*\\*2 )\n",
    "\n",
    "Generator: 0.5 \\*  (D(G(z)) - 1)\\*\\*2 \n",
    "\n",
    "This means we assign the real images a label of 1 and the fake images a label of 0. The generator tries to force the discriminator to output 1 for its images. This is already implemented in pytorch with `torch.nn.MSELoss()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c1e3738",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSGAN(AbstractGAN1v1):\n",
    "    def __init__(\n",
    "            self,\n",
    "            generator,\n",
    "            adversary,\n",
    "            x_dim,\n",
    "            z_dim,\n",
    "            optim=None,\n",
    "            optim_kwargs=None,\n",
    "            fixed_noise_size=32,\n",
    "            device=None,\n",
    "            folder=\"./VanillaGAN\",\n",
    "            ngpu=None):\n",
    "\n",
    "        super().__init__(\n",
    "            generator=generator, adversary=adversary,\n",
    "            z_dim=z_dim, x_dim=x_dim, adv_type=\"Discriminator\",\n",
    "            optim=optim, optim_kwargs=optim_kwargs,\n",
    "            fixed_noise_size=fixed_noise_size,\n",
    "            device=device, folder=folder, ngpu=ngpu\n",
    "        )\n",
    "\n",
    "    def _define_loss(self):\n",
    "        self.loss_functions = {\"Generator\": torch.nn.MSELoss(), \"Adversary\": torch.nn.MSELoss()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5240f406",
   "metadata": {},
   "source": [
    "We chose the `torch.optim.Adam` optimizer as a default optimizer and implemented the appropriate loss. The parent classes `AbstractGAN1v1` and `AbstractGenerativeModel` will take care of all the rest. For example if `who=\"Generator\"`, the following code snippet is called:\n",
    "\n",
    "```python\n",
    "def _calculate_generator_loss(self, X_batch, Z_batch):\n",
    "    fake_images = self.generate(z=Z_batch)\n",
    "    fake_predictions = self.predict(x=fake_images)\n",
    "    gen_loss = self.loss_functions[\"Generator\"](\n",
    "        fake_predictions, torch.ones_like(fake_predictions, requires_grad=False)\n",
    "    )\n",
    "    self._losses.update({\"Generator\": gen_loss})\n",
    "``` \n",
    "\n",
    "So a normal least squares loss is calculated between the output of the discriminator for generated images: `D(G(z)) -> self.predict(self.generate(z=Z_batch))` and labels 1 (because c=1). This is saved in the `self._losses` dict which is used by the `AbstractGenerativeModel` to perform optimization. A similar function is called for the adversary, for completeness stated here:\n",
    "\n",
    "```python\n",
    "def _calculate_adversary_loss(self, X_batch, Z_batch):\n",
    "    fake_images = self.generate(z=Z_batch).detach()\n",
    "    fake_predictions = self.predict(x=fake_images)\n",
    "    real_predictions = self.predict(x=X_batch.float())\n",
    "\n",
    "    adv_loss_fake = self.loss_functions[\"Adversary\"](\n",
    "        fake_predictions, torch.zeros_like(fake_predictions, requires_grad=False)\n",
    "    )\n",
    "    adv_loss_real = self.loss_functions[\"Adversary\"](\n",
    "        real_predictions, torch.ones_like(real_predictions, requires_grad=False)\n",
    "    )\n",
    "    adv_loss = 0.5*(adv_loss_fake + adv_loss_real)\n",
    "    self._losses.update({\n",
    "        \"Adversary\": adv_loss,\n",
    "        \"Adversary_fake\": adv_loss_fake,\n",
    "        \"Adversary_real\": adv_loss_real,\n",
    "    })\n",
    "``` \n",
    "\n",
    "Please be aware that this is the code snippet at the time of writing. It may change in the future but will probably not change drastically from this implementation.\n",
    "\n",
    "The network would now be ready to be used :)\n",
    "\n",
    "But we won't stop here and go quickly over the implementation of the `ConditionalLSGAN` so we can take labels and images as conditional input.\n",
    "\n",
    "## ConditionalLSGAN\n",
    "\n",
    "We can basically do the same thing as before and copy from [CondtionalVanillaGAN](https://github.com/tneuer/GAN-pytorch/blob/main/vegans/models/conditional/ConditionalVanillaGAN.py). This time we will inherit from `AbstractConditionalGAN1v1` (which inherits from `AbstractConditionalGenerativeModel` which in turn inherits from `AbstractGenerativeModel`). Everything is a `AbstractGenerativeModel` in the end. \n",
    "\n",
    "The main difference is that we now must also pass the `y_dim` (Dimension of the labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "970bfd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vegans.models.unconditional.LSGAN import LSGAN\n",
    "from vegans.models.conditional.AbstractConditionalGAN1v1 import AbstractConditionalGAN1v1\n",
    "\n",
    "class ConditionalLSGAN(AbstractConditionalGAN1v1, LSGAN):\n",
    "    def __init__(\n",
    "            self,\n",
    "            generator,\n",
    "            adversary,\n",
    "            x_dim,\n",
    "            z_dim,\n",
    "            y_dim,\n",
    "            optim=None,\n",
    "            optim_kwargs=None,\n",
    "            feature_layer=None,\n",
    "            fixed_noise_size=32,\n",
    "            device=None,\n",
    "            folder=\"./ConditionalVanillaGAN\",\n",
    "            ngpu=None):\n",
    "\n",
    "        super().__init__(\n",
    "            generator=generator, adversary=adversary,\n",
    "            x_dim=x_dim, z_dim=z_dim, y_dim=y_dim, adv_type=\"Discriminator\",\n",
    "            optim=optim, optim_kwargs=optim_kwargs, feature_layer=feature_layer,\n",
    "            fixed_noise_size=fixed_noise_size,\n",
    "            device=device, folder=folder, ngpu=ngpu\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56225be4",
   "metadata": {},
   "source": [
    "This is all we had to do. The rest is handled by the two parent classes. This algorithm should now be possible to generate specific instances of handwritten digits or even translate an image of a summer scenery into winter scenery (note that there are other special architectures for especially this last problem, like BiCycleGAN). It was pretty easy to implement this network due to the abstractions that were in place. In the next session we will implement a Pix2PixGAN which requires some additonal modification of the loss function but also shouldn't be too difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c77f805",
   "metadata": {},
   "source": [
    "Please again note that this is a prelimanary tutorial implementation which might or might not change in future releases of `vegans`. So this implementation might not be completely up-to-date, but still is a viable implementation nonetheless."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
